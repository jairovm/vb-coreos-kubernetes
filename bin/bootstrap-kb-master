#!/usr/bin/env ruby
require 'optparse'
require 'fileutils'

class Bootstrapper
  ROOT_PATH  = File.expand_path('../../', __FILE__).freeze
  CERTS_DIR  = File.join(ROOT_PATH, 'assets/certs').freeze

  attr_accessor :options

  def initialize(arguments)
    parse arguments
  end

  def process
    exit 1 unless valid?

    copy_certs
    configure_flannel
    configure_docker
    configure_kubelet
    configure_kube_apiserver
    configure_kube_proxy
    configure_kube_controller_manager
    configure_kube_scheduler
  end

private

  def copy_certs
    home_path = %x(ssh #{options[:master_host]} pwd).strip

    ssh "sudo mkdir -p /etc/kubernetes/ssl"

    %w[ca.pem apiserver.crt apiserver-key.pem].each do |file|
      scp File.join(CERTS_DIR, file), "#{home_path}/#{file}"
      ssh "sudo mv #{home_path}/#{file} /etc/kubernetes/ssl/#{file}"
      ssh "sudo chown root:root /etc/kubernetes/ssl/#{file}"
    end

    ssh "sudo chmod 600 /etc/kubernetes/ssl/*-key.pem"
  end

  def configure_flannel
    ssh <<-EOS
      sudo mkdir -p /etc/flannel /etc/systemd/system/flanneld.service.d

      sudo echo "\
FLANNELD_IFACE=#{options[:master_host]}
FLANNELD_ETCD_ENDPOINTS=#{options[:etcd_endpoints].join(',')}"\
        | sudo tee /etc/flannel/options.env > /dev/null

      sudo echo "\
[Service]
ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env"\
        | sudo tee /etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf > /dev/null
    EOS
  end

  def configure_docker
    ssh <<-EOS
      sudo mkdir -p /etc/systemd/system/docker.service.d /etc/kubernetes/cni/net.d

      sudo echo "\
[Unit]
Requires=flanneld.service
After=flanneld.service
[Service]
EnvironmentFile=/run/flannel/flannel_docker_opts.env"\
      | sudo tee /etc/systemd/system/docker.service.d/40-flannel.conf > /dev/null

      sudo echo "\
{
    \\"name\\": \\"podnet\\",
    \\"type\\": \\"flannel\\",
    \\"delegate\\": {
        \\"isDefaultGateway\\": true
    }
}"\
      | sudo tee /etc/kubernetes/cni/net.d/10-flannel.conf > /dev/null
    EOS
  end

  def configure_kubelet
    ssh <<-EOS
      sudo echo "\
[Service]
Environment=KUBELET_IMAGE_TAG=v1.5.2_coreos.0
Environment="RKT_RUN_ARGS=--uuid-file-save=/var/run/kubelet-pod.uuid \
  --volume var-log,kind=host,source=/var/log \
  --mount volume=var-log,target=/var/log \
  --volume dns,kind=host,source=/etc/resolv.conf \
  --mount volume=dns,target=/etc/resolv.conf"
ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
ExecStartPre=/usr/bin/mkdir -p /var/log/containers
ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid
ExecStart=/usr/lib/coreos/kubelet-wrapper \
  --api-servers=http://127.0.0.1:8080 \
  --register-schedulable=false \
  --cni-conf-dir=/etc/kubernetes/cni/net.d \
  --container-runtime=docker \
  --allow-privileged=true \
  --pod-manifest-path=/etc/kubernetes/manifests \
  --hostname-override=#{options[:master_host]} \
  --cluster_dns=10.3.0.10 \
  --cluster_domain=cluster.local
ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target"\
      | sudo tee /etc/systemd/system/kubelet.service > /dev/null
    EOS
  end

  def configure_kube_apiserver
    ssh <<-EOS
      sudo mkdir -p /etc/kubernetes/manifests

      sudo echo "\
apiVersion: v1
kind: Pod
metadata:
  name: kube-apiserver
  namespace: kube-system
spec:
  hostNetwork: true
  containers:
  - name: kube-apiserver
    image: quay.io/coreos/hyperkube:v1.5.2_coreos.0
    command:
    - /hyperkube
    - apiserver
    - --bind-address=0.0.0.0
    - --etcd-servers=#{options[:etcd_endpoints].join(',')}
    - --allow-privileged=true
    - --service-cluster-ip-range=10.3.0.0/24
    - --secure-port=443
    - --advertise-address=#{options[:master_host]}
    - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota
    - --tls-cert-file=/etc/kubernetes/ssl/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
    - --client-ca-file=/etc/kubernetes/ssl/ca.pem
    - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
    - --runtime-config=extensions/v1beta1/networkpolicies=true
    - --anonymous-auth=false
    livenessProbe:
      httpGet:
        host: 127.0.0.1
        port: 8080
        path: /healthz
      initialDelaySeconds: 15
      timeoutSeconds: 15
    ports:
    - containerPort: 443
      hostPort: 443
      name: https
    - containerPort: 8080
      hostPort: 8080
      name: local
    volumeMounts:
    - mountPath: /etc/kubernetes/ssl
      name: ssl-certs-kubernetes
      readOnly: true
    - mountPath: /etc/ssl/certs
      name: ssl-certs-host
      readOnly: true
  volumes:
  - hostPath:
      path: /etc/kubernetes/ssl
    name: ssl-certs-kubernetes
  - hostPath:
      path: /usr/share/ca-certificates
    name: ssl-certs-host"\
      | sudo tee /etc/kubernetes/manifests/kube-apiserver.yaml > /dev/null
    EOS
  end

  def configure_kube_proxy
    ssh <<-EOS
      sudo mkdir -p /etc/kubernetes/manifests

      sudo echo "\
apiVersion: v1
kind: Pod
metadata:
  name: kube-proxy
  namespace: kube-system
spec:
  hostNetwork: true
  containers:
  - name: kube-proxy
    image: quay.io/coreos/hyperkube:v1.5.2_coreos.0
    command:
    - /hyperkube
    - proxy
    - --master=http://127.0.0.1:8080
    securityContext:
      privileged: true
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ssl-certs-host
      readOnly: true
  volumes:
  - hostPath:
      path: /usr/share/ca-certificates
    name: ssl-certs-host"\
      | sudo tee /etc/kubernetes/manifests/kube-proxy.yaml > /dev/null
    EOS
  end

  def configure_kube_controller_manager
    ssh <<-EOS
      sudo mkdir -p /etc/kubernetes/manifests

      sudo echo "\
apiVersion: v1
kind: Pod
metadata:
  name: kube-controller-manager
  namespace: kube-system
spec:
  hostNetwork: true
  containers:
  - name: kube-controller-manager
    image: quay.io/coreos/hyperkube:v1.5.2_coreos.0
    command:
    - /hyperkube
    - controller-manager
    - --master=http://127.0.0.1:8080
    - --leader-elect=true
    - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
    - --root-ca-file=/etc/kubernetes/ssl/ca.pem
    resources:
      requests:
        cpu: 200m
    livenessProbe:
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10252
      initialDelaySeconds: 15
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/kubernetes/ssl
      name: ssl-certs-kubernetes
      readOnly: true
    - mountPath: /etc/ssl/certs
      name: ssl-certs-host
      readOnly: true
  hostNetwork: true
  volumes:
  - hostPath:
      path: /etc/kubernetes/ssl
    name: ssl-certs-kubernetes
  - hostPath:
      path: /usr/share/ca-certificates
    name: ssl-certs-host"\
      | sudo tee /etc/kubernetes/manifests/kube-controller-manager.yaml > /dev/null
    EOS
  end

  def configure_kube_scheduler
    ssh <<-EOS
      sudo mkdir -p /etc/kubernetes/manifests

      sudo echo "\
apiVersion: v1
kind: Pod
metadata:
  name: kube-scheduler
  namespace: kube-system
spec:
  hostNetwork: true
  containers:
  - name: kube-scheduler
    image: quay.io/coreos/hyperkube:v1.5.2_coreos.0
    command:
    - /hyperkube
    - scheduler
    - --master=http://127.0.0.1:8080
    - --leader-elect=true
    resources:
      requests:
        cpu: 100m
    livenessProbe:
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10251
      initialDelaySeconds: 15
      timeoutSeconds: 15"\
      | sudo tee /etc/kubernetes/manifests/kube-scheduler.yaml > /dev/null
    EOS
  end

  def ssh(cmd)
    system %{ssh #{options[:master_host]} '#{cmd}'}
  end

  def scp(from, to)
    system "scp #{from} #{options[:master_host]}:#{to}"
  end

  def valid?
    errors = []
    errors << '--master-host is required'     if options[:master_host].nil?
    errors << '--etcd-endpoints are required' if options[:etcd_endpoints].empty?

    $stderr.puts errors.join("\n") unless errors.empty?
    errors.empty?
  end

  def parse(arguments)
    self.options = {}

    OptionParser.new do |opts|
      opts.banner = "Usage: bin/bootstrap-kb-master [options]"

      opts.on(
        '--master-host MASTER_HOST',
        'The address of the master node'
      ) do |master_host|
        options[:master_host] = master_host
      end

      options[:etcd_endpoints] = []
      opts.on('--etcd-endpoints IP,IP...', Array, 'Etcd cluster endpoints') do |ips|
        options[:etcd_endpoints] = ips
      end

      opts.on('-h', '--help', 'Display this screen') do
        puts opts
        exit
      end
    end.parse!(arguments)
  end
end

Bootstrapper.new(ARGV).process
